
@incollection{chanDeepLearningMedical2020,
	address = {Cham},
	series = {Advances in {Experimental} {Medicine} and {Biology}},
	title = {Deep {Learning} in {Medical} {Image} {Analysis}},
	isbn = {978-3-030-33128-3},
	url = {https://doi.org/10.1007/978-3-030-33128-3_1},
	abstract = {Deep learning is the state-of-the-art machine learning approach. The success of deep learning in many pattern recognition applications has brought excitement and high expectations that deep learning, or artificial intelligence (AI), can bring revolutionary changes in health care. Early studies of deep learning applied to lesion detection or classification have reported superior performance compared to those by conventional techniques or even better than radiologists in some tasks. The potential of applying deep-learning-based medical image analysis to computer-aided diagnosis (CAD), thus providing decision support to clinicians and improving the accuracy and efficiency of various diagnostic and treatment processes, has spurred new research and development efforts in CAD. Despite the optimism in this new era of machine learning, the development and implementation of CAD or AI tools in clinical practice face many challenges. In this chapter, we will discuss some of these issues and efforts needed to develop robust deep-learning-based CAD tools and integrate these tools into the clinical workflow, thereby advancing towards the goal of providing reliable intelligent aids for patient care.},
	language = {en},
	urldate = {2023-03-06},
	booktitle = {Deep {Learning} in {Medical} {Image} {Analysis} : {Challenges} and {Applications}},
	publisher = {Springer International Publishing},
	author = {Chan, Heang-Ping and Samala, Ravi K. and Hadjiiski, Lubomir M. and Zhou, Chuan},
	editor = {Lee, Gobert and Fujita, Hiroshi},
	year = {2020},
	doi = {10.1007/978-3-030-33128-3_1},
	keywords = {Artificial intelligence, Big data, Computer-aided diagnosis, Deep learning, Interpretable AI, Machine learning, Medical imaging, Quality assurance, Transfer learning, Validation},
	pages = {3--21},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/2YVEZVI4/Chan et al. - 2020 - Deep Learning in Medical Image Analysis.pdf:application/pdf},
}

@article{sarvamangalaConvolutionalNeuralNetworks2022,
	title = {Convolutional neural networks in medical image understanding: a survey},
	volume = {15},
	issn = {1864-5917},
	shorttitle = {Convolutional neural networks in medical image understanding},
	url = {https://doi.org/10.1007/s12065-020-00540-3},
	doi = {10.1007/s12065-020-00540-3},
	abstract = {Imaging techniques are used to capture anomalies of the human body. The captured images must be understood for diagnosis, prognosis and treatment planning of the anomalies. Medical image understanding is generally performed by skilled medical professionals. However, the scarce availability of human experts and the fatigue and rough estimate procedures involved with them limit the effectiveness of image understanding performed by skilled medical professionals. Convolutional neural networks (CNNs) are effective tools for image understanding. They have outperformed human experts in many image understanding tasks. This article aims to provide a comprehensive survey of applications of CNNs in medical image understanding. The underlying objective is to motivate medical image understanding researchers to extensively apply CNNs in their research and diagnosis. A brief introduction to CNNs has been presented. A discussion on CNN and its various award-winning frameworks have been presented. The major medical image understanding tasks, namely image classification, segmentation, localization and detection have been introduced. Applications of CNN in medical image understanding of the ailments of brain, breast, lung and other organs have been surveyed critically and comprehensively. A critical discussion on some of the challenges is also presented.},
	language = {en},
	number = {1},
	urldate = {2023-03-06},
	journal = {Evolutionary Intelligence},
	author = {Sarvamangala, D. R. and Kulkarni, Raghavendra V.},
	month = mar,
	year = {2022},
	keywords = {Classification, Convolutional neural networks, Detection, Image understanding, Localization, Segmentation},
	pages = {1--22},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/7LGRTT9K/Sarvamangala and Kulkarni - 2022 - Convolutional neural networks in medical image und.pdf:application/pdf},
}

@article{tajbakhshConvolutionalNeuralNetworks2016,
	title = {Convolutional {Neural} {Networks} for {Medical} {Image} {Analysis}: {Full} {Training} or {Fine} {Tuning}?},
	volume = {35},
	issn = {1558-254X},
	shorttitle = {Convolutional {Neural} {Networks} for {Medical} {Image} {Analysis}},
	doi = {10.1109/TMI.2016.2535302},
	abstract = {Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.},
	number = {5},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Tajbakhsh, Nima and Shin, Jae Y. and Gurudu, Suryakanth R. and Hurst, R. Todd and Kendall, Christopher B. and Gotway, Michael B. and Liang, Jianming},
	month = may,
	year = {2016},
	note = {Conference Name: IEEE Transactions on Medical Imaging},
	keywords = {Biomedical imaging, Carotid intima-media thickness, Computed tomography, computer-aided detection, convolutional neural networks, deep learning, Feature extraction, fine-tuning, Image analysis, Image segmentation, medical image analysis, polyp detection, pulmonary embolism detection, Training, Tuning, video quality assessment},
	pages = {1299--1312},
	file = {IEEE Xplore Abstract Record:/Users/noltinho/Zotero/storage/VYJJ8276/7426826.html:text/html;IEEE Xplore Full Text PDF:/Users/noltinho/Zotero/storage/MAFWU8B4/Tajbakhsh et al. - 2016 - Convolutional Neural Networks for Medical Image An.pdf:application/pdf},
}

@article{yuConvolutionalNeuralNetworks2021,
	title = {Convolutional neural networks for medical image analysis: {State}-of-the-art, comparisons, improvement and perspectives},
	volume = {444},
	issn = {0925-2312},
	shorttitle = {Convolutional neural networks for medical image analysis},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231221001314},
	doi = {10.1016/j.neucom.2020.04.157},
	abstract = {Convolutional neural networks, are one of the most representative deep learning models. CNNs were extensively used in many aspects of medical image analysis, allowing for great progress in computer-aided diagnosis in recent years. In this paper, we provide a survey on convolutional neural networks in medical image analysis. First, we review the commonly used CNNs in medical image processing, including AlexNet, GoogleNet, ResNet, R-CNN, and FCNN. Then, we present an overview of the use of CNNs, for image classification, segmentation, detection, and other tasks such as registration, content-based image retrieval, image generation and enhancement, in some typical medical diagnosis areas such as brain, breast, and abdominal. Finally, we discuss the remaining challenges of CNNs in medical image analysis, and accordingly we present some ideas for future research directions.},
	language = {en},
	urldate = {2023-03-06},
	journal = {Neurocomputing},
	author = {Yu, Hang and Yang, Laurence T. and Zhang, Qingchen and Armstrong, David and Deen, M. Jamal},
	month = jul,
	year = {2021},
	keywords = {Classification, Convolutional neural networks, Medical image analysis, Smart medicine},
	pages = {92--110},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/GRVX6KUG/Yu et al. - 2021 - Convolutional neural networks for medical image an.pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/93MNCHP6/S0925231221001314.html:text/html},
}

@article{yadavDeepConvolutionalNeural2019,
	title = {Deep convolutional neural network based medical image classification for disease diagnosis},
	volume = {6},
	issn = {2196-1115},
	url = {https://doi.org/10.1186/s40537-019-0276-2},
	doi = {10.1186/s40537-019-0276-2},
	abstract = {Medical image classification plays an essential role in clinical treatment and teaching tasks. However, the traditional method has reached its ceiling on performance. Moreover, by using them, much time and effort need to be spent on extracting and selecting classification features. The deep neural network is an emerging machine learning method that has proven its potential for different classification tasks. Notably, the convolutional neural network dominates with the best results on varying image classification tasks. However, medical image datasets are hard to collect because it needs a lot of professional expertise to label them. Therefore, this paper researches how to apply the convolutional neural network (CNN) based algorithm on a chest X-ray dataset to classify pneumonia. Three techniques are evaluated through experiments. These are linear support vector machine classifier with local rotation and orientation free features, transfer learning on two convolutional neural network models: Visual Geometry Group i.e., VGG16 and InceptionV3, and a capsule network training from scratch. Data augmentation is a data preprocessing method applied to all three methods. The results of the experiments show that data augmentation generally is an effective way for all three algorithms to improve performance. Also, Transfer learning is a more useful classification method on a small dataset compared to a support vector machine with oriented fast and rotated binary (ORB) robust independent elementary features and capsule network. In transfer learning, retraining specific features on a new target dataset is essential to improve performance. And, the second important factor is a proper network complexity that matches the scale of the dataset.},
	language = {en},
	number = {1},
	urldate = {2023-03-06},
	journal = {Journal of Big Data},
	author = {Yadav, Samir S. and Jadhav, Shivajirao M.},
	month = dec,
	year = {2019},
	keywords = {Transfer learning, Capsule network, CNN, Image classification, ORB, SVM},
	pages = {113},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/GFETRHTI/Yadav and Jadhav - 2019 - Deep convolutional neural network based medical im.pdf:application/pdf},
}

@article{jinGuidelinesEvaluationClinical2023,
	title = {Guidelines and evaluation of clinical explainable {AI} in medical image analysis},
	volume = {84},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522003127},
	doi = {10.1016/j.media.2022.102684},
	abstract = {Explainable artificial intelligence (XAI) is essential for enabling clinical users to get informed decision support from AI and comply with evidence-based medical practice. Applying XAI in clinical settings requires proper evaluation criteria to ensure the explanation technique is both technically sound and clinically useful, but specific support is lacking to achieve this goal. To bridge the research gap, we propose the Clinical XAI Guidelines that consist of five criteria a clinical XAI needs to be optimized for. The guidelines recommend choosing an explanation form based on Guideline 1 (G1) Understandability and G2 Clinical relevance. For the chosen explanation form, its specific XAI technique should be optimized for G3 Truthfulness, G4 Informative plausibility, and G5 Computational efficiency. Following the guidelines, we conducted a systematic evaluation on a novel problem of multi-modal medical image explanation with two clinical tasks, and proposed new evaluation metrics accordingly. Sixteen commonly-used heatmap XAI techniques were evaluated and found to be insufficient for clinical use due to their failure in G3 and G4. Our evaluation demonstrated the use of Clinical XAI Guidelines to support the design and evaluation of clinically viable XAI.},
	language = {en},
	urldate = {2023-03-06},
	journal = {Medical Image Analysis},
	author = {Jin, Weina and Li, Xiaoxiao and Fatehi, Mostafa and Hamarneh, Ghassan},
	month = feb,
	year = {2023},
	keywords = {Medical image analysis, Explainable AI evaluation, Interpretable machine learning, Multi-modal medical image},
	pages = {102684},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/ULEH6VTS/Jin et al. - 2023 - Guidelines and evaluation of clinical explainable .pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/SDS6SJCF/S1361841522003127.html:text/html},
}

@misc{chenMed3DTransferLearning2019,
	title = {{Med3D}: {Transfer} {Learning} for {3D} {Medical} {Image} {Analysis}},
	shorttitle = {{Med3D}},
	url = {http://arxiv.org/abs/1904.00625},
	doi = {10.48550/arXiv.1904.00625},
	abstract = {The performance on deep learning is significantly affected by volume of training data. Models pre-trained from massive dataset such as ImageNet become a powerful weapon for speeding up training convergence and improving accuracy. Similarly, models based on large dataset are important for the development of deep learning in 3D medical images. However, it is extremely challenging to build a sufficiently large dataset due to difficulty of data acquisition and annotation in 3D medical imaging. We aggregate the dataset from several medical challenges to build 3DSeg-8 dataset with diverse modalities, target organs, and pathologies. To extract general medical three-dimension (3D) features, we design a heterogeneous 3D network called Med3D to co-train multi-domain 3DSeg-8 so as to make a series of pre-trained models. We transfer Med3D pre-trained models to lung segmentation in LIDC dataset, pulmonary nodule classification in LIDC dataset and liver segmentation on LiTS challenge. Experiments show that the Med3D can accelerate the training convergence speed of target 3D medical tasks 2 times compared with model pre-trained on Kinetics dataset, and 10 times compared with training from scratch as well as improve accuracy ranging from 3\% to 20\%. Transferring our Med3D model on state-the-of-art DenseASPP segmentation network, in case of single model, we achieve 94.6{\textbackslash}\% Dice coefficient which approaches the result of top-ranged algorithms on the LiTS challenge.},
	urldate = {2023-03-06},
	publisher = {arXiv},
	author = {Chen, Sihong and Ma, Kai and Zheng, Yefeng},
	month = jul,
	year = {2019},
	note = {arXiv:1904.00625 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv Fulltext PDF:/Users/noltinho/Zotero/storage/F2GNTU8B/Chen et al. - 2019 - Med3D Transfer Learning for 3D Medical Image Anal.pdf:application/pdf;arXiv.org Snapshot:/Users/noltinho/Zotero/storage/HAGRXGC5/1904.html:text/html},
}

@article{chenRecentAdvancesClinical2022,
	title = {Recent advances and clinical applications of deep learning in medical image analysis},
	volume = {79},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522000913},
	doi = {10.1016/j.media.2022.102444},
	abstract = {Deep learning has received extensive research interest in developing new medical image processing algorithms, and deep learning based models have been remarkably successful in a variety of medical imaging tasks to support disease detection and diagnosis. Despite the success, the further improvement of deep learning models in medical image analysis is majorly bottlenecked by the lack of large-sized and well-annotated datasets. In the past five years, many studies have focused on addressing this challenge. In this paper, we reviewed and summarized these recent studies to provide a comprehensive overview of applying deep learning methods in various medical image analysis tasks. Especially, we emphasize the latest progress and contributions of state-of-the-art unsupervised and semi-supervised deep learning in medical image analysis, which are summarized based on different application scenarios, including classification, segmentation, detection, and image registration. We also discuss major technical challenges and suggest possible solutions in the future research efforts.},
	language = {en},
	urldate = {2023-03-06},
	journal = {Medical Image Analysis},
	author = {Chen, Xuxin and Wang, Ximin and Zhang, Ke and Fung, Kar-Ming and Thai, Theresa C. and Moore, Kathleen and Mannel, Robert S. and Liu, Hong and Zheng, Bin and Qiu, Yuchen},
	month = jul,
	year = {2022},
	keywords = {Deep learning, Classification, Detection, Segmentation, Attention, Medical images, Registration, Self-supervised learning, Semi-supervised learning, Unsupervised learning, Vision Transformer},
	pages = {102444},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/WM4VPQR3/Chen et al. - 2022 - Recent advances and clinical applications of deep .pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/4WGNP6BU/S1361841522000913.html:text/html},
}

@article{xiaoTaskRelevanceDriven2022,
	title = {Task relevance driven adversarial learning for simultaneous detection, size grading, and quantification of hepatocellular carcinoma via integrating multi-modality {MRI}},
	volume = {81},
	issn = {1361-8415},
	url = {https://www.sciencedirect.com/science/article/pii/S1361841522002018},
	doi = {10.1016/j.media.2022.102554},
	abstract = {Hepatocellular Carcinoma (HCC) detection, size grading, and quantification (i.e. the center point coordinates, max-diameter, and area) by using multi-modality magnetic resonance imaging (MRI) are clinically significant tasks for HCC assessment and treatment. However, delivering the three tasks simultaneously is extremely challenging due to: (1) the lack of effective an mechanism to capture the relevance among multi-modality MRI information for multi-modality feature fusion and selection; (2) the lack of effective mechanism and constraint strategy to achieve mutual promotion of multi-task. In this paper, we proposed a task relevance driven adversarial learning framework (TrdAL) for simultaneous HCC detection, size grading, and multi-index quantification using multi-modality MRI (i.e. in-phase, out-phase, T2FS, and DWI). The TrdAL first obtains expressive feature of dimension reduction via using a CNN-based encoder. Secondly, the proposed modality-aware Transformer is utilized for multi-modality MRI features fusion and selection, which solves the challenge of multi-modality information diversity via capturing the relevance among multi-modality MRI. Then, the innovative task relevance driven and radiomics guided discriminator (Trd-Rg-D) is used for united adversarial learning. The Trd-Rg-D captures the internal high-order relationships to refine the performance of multi-task simultaneously. Moreover, adding the radiomics feature as the prior knowledge into Trd-Rg-D enhances the detailed feature extraction. Lastly, a novel task interaction loss function is used for constraining the TrdAL, which enforces the higher-order consistency among multi-task labels to enhance mutual promotion. The TrdAL is validated on a corresponding multi-modality MRI of 135 subjects. The experiments demonstrate that TrdAL achieves high accuracy of (1) HCC detection: specificity of 93.71\%, sensitivity of 93.15\%, accuracy of 93.33\%, and IoU of 82.93\%; (2) size grading: accuracy of large size, medium size, small size, tiny size, and healthy subject are 90.38\%, 87.74\%, 80.68\%, 77.78\%, and 96.87\%; (3) multi-index quantification: the mean absolute error of center point, max-diameter, and area are 2.74mm, 3.17mm, and 144.51mm2. All of these results indicate that the proposed TrdAL provides an efficient, accurate, and reliable tool for HCC diagnosis in clinical.},
	language = {en},
	urldate = {2023-03-06},
	journal = {Medical Image Analysis},
	author = {Xiao, Xiaojiao and Zhao, Jianfeng and Li, Shuo},
	month = oct,
	year = {2022},
	keywords = {Adversarial learning, Hepatocellular carcinoma, Modality-aware transformer, Multi-modality, Multi-task},
	pages = {102554},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/JAJHTXR5/Xiao et al. - 2022 - Task relevance driven adversarial learning for sim.pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/7KXGDUYX/S1361841522002018.html:text/html},
}

@article{jimenezperezApplicationArtificialIntelligence2020,
	title = {Application of artificial intelligence in the diagnosis and treatment of hepatocellular carcinoma: {A} review},
	volume = {26},
	issn = {1007-9327},
	shorttitle = {Application of artificial intelligence in the diagnosis and treatment of hepatocellular carcinoma},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7545389/},
	doi = {10.3748/wjg.v26.i37.5617},
	abstract = {Although artificial intelligence (AI) was initially developed many years ago, it has experienced spectacular advances over the last 10 years for application in the field of medicine, and is now used for diagnostic, therapeutic and prognostic purposes in almost all fields. Its application in the area of hepatology is especially relevant for the study of hepatocellular carcinoma (HCC), as this is a very common tumor, with particular radiological characteristics that allow its diagnosis without the need for a histological study. However, the interpretation and analysis of the resulting images is not always easy, in addition to which the images vary during the course of the disease, and prognosis and treatment response can be conditioned by multiple factors. The vast amount of data available lend themselves to study and analysis by AI in its various branches, such as deep-learning (DL) and machine learning (ML), which play a fundamental role in decision-making as well as overcoming the constraints involved in human evaluation. ML is a form of AI based on automated learning from a set of previously provided data and training in algorithms to organize and recognize patterns. DL is a more extensive form of learning that attempts to simulate the working of the human brain, using a lot more data and more complex algorithms. This review specifies the type of AI used by the various authors. However, well-designed prospective studies are needed in order to avoid as far as possible any bias that may later affect the interpretability of the images and thereby limit the acceptance and application of these models in clinical practice. In addition, professionals now need to understand the true usefulness of these techniques, as well as their associated strengths and limitations.},
	number = {37},
	urldate = {2023-03-20},
	journal = {World Journal of Gastroenterology},
	author = {Jiménez Pérez, Miguel and Grande, Rocío González},
	month = oct,
	year = {2020},
	pmid = {33088156},
	pmcid = {PMC7545389},
	pages = {5617--5628},
	file = {PubMed Central Full Text PDF:/Users/noltinho/Zotero/storage/NA9U6FUI/Jiménez Pérez and Grande - 2020 - Application of artificial intelligence in the diag.pdf:application/pdf},
}

@article{parraAdvancementsDiagnosisHepatocellular2023,
	title = {Advancements in the {Diagnosis} of {Hepatocellular} {Carcinoma}},
	volume = {3},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2673-8937},
	url = {https://www.mdpi.com/2673-8937/3/1/5},
	doi = {10.3390/ijtm3010005},
	abstract = {Hepatocellular carcinoma (HCC) is the most common primary liver malignancy, with increasing global incidence. Morbidity and mortality associated with HCC remains high, and HCC is the leading cause of cancer death worldwide. Early detection and treatment of HCC can increase five-year survival by over 60\%. Detection of HCC remains challenging, however, as HCC arises from a variety of environmental, genetic, and viral etiologies, and it demonstrates a complex pathophysiology and displays a heterogeneous morphology. Current diagnostic methods rely on abdominal ultrasound with or without concurrent AFP biomarker testing for high-risk individuals. This review provides an overview of HCC diagnostic modalities and highlights the promising nature of translational developments in biomarkers, next generation sequencing (NGS), artificial intelligence, molecular imaging, and liquid biopsy for earlier and more accurate diagnosis of HCC. Furthermore, we identify areas for improvement that must be addressed before the widespread usage and implementation of these methods.},
	language = {en},
	number = {1},
	urldate = {2023-03-20},
	journal = {International Journal of Translational Medicine},
	author = {Parra, Natalia Salinas and Ross, Heather M. and Khan, Adnan and Wu, Marisa and Goldberg, Risa and Shah, Lokesh and Mukhtar, Sarah and Beiriger, Jacob and Gerber, Alexis and Halegoua-DeMarzio, Dina},
	month = mar,
	year = {2023},
	note = {Number: 1
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {artificial intelligence, biomarkers, HCC, liquid biopsy, molecular imaging, NGS},
	pages = {51--65},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/BPGJR5ZF/Parra et al. - 2023 - Advancements in the Diagnosis of Hepatocellular Ca.pdf:application/pdf},
}

@article{pellatArtificialIntelligenceReview2023,
	title = {Artificial intelligence: {A} review of current applications in hepatocellular carcinoma imaging},
	volume = {104},
	issn = {2211-5684},
	shorttitle = {Artificial intelligence},
	url = {https://www.sciencedirect.com/science/article/pii/S2211568422001899},
	doi = {10.1016/j.diii.2022.10.001},
	abstract = {Hepatocellular carcinoma (HCC) is the most common type of primary liver cancer and currently the third-leading cause of cancer-related death worldwide. Recently, artificial intelligence (AI) has emerged as an important tool to improve clinical management of HCC, including for diagnosis, prognostication and evaluation of treatment response. Different AI approaches, such as machine learning and deep learning, are both based on the concept of developing prediction algorithms from large amounts of data, or big data. The era of digital medicine has led to a rapidly expanding amount of routinely collected health data which can be leveraged for the development of AI models. Various studies have constructed AI models by using features extracted from ultrasound imaging, computed tomography imaging and magnetic resonance imaging. Most of these models have used convolutional neural networks. These tools have shown promising results for HCC detection, characterization of liver lesions and liver/tumor segmentation. Regarding treatment, studies have outlined a role for AI in evaluation of treatment response and improvement of pre-treatment planning. Several challenges remain to fully integrate AI models in clinical practice. Future research is still needed to robustly evaluate AI algorithms in prospective trials, and improve interpretability, generalizability and transparency. If such challenges can be overcome, AI has the potential to profoundly change the management of patients with HCC. The purpose of this review was to sum up current evidence on AI approaches using imaging for the clinical management of HCC.},
	language = {en},
	number = {1},
	urldate = {2023-03-20},
	journal = {Diagnostic and Interventional Imaging},
	author = {Pellat, Anna and Barat, Maxime and Coriat, Romain and Soyer, Philippe and Dohan, Anthony},
	month = jan,
	year = {2023},
	keywords = {Artificial intelligence, Deep learning, Machine learning, Hepatocellular carcinoma, Diagnosis, Treatment},
	pages = {24--36},
	file = {ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/TZY39EJ5/S2211568422001899.html:text/html},
}

@article{wolfUseHepatocellularCarcinoma2021,
	title = {Use of {Hepatocellular} {Carcinoma} {Surveillance} in {Patients} {With} {Cirrhosis}: {A} {Systematic} {Review} and {Meta}-{Analysis}},
	volume = {73},
	issn = {1527-3350},
	shorttitle = {Use of {Hepatocellular} {Carcinoma} {Surveillance} in {Patients} {With} {Cirrhosis}},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hep.31309},
	doi = {10.1002/hep.31309},
	abstract = {Background and Aims Hepatocellular carcinoma (HCC) surveillance is associated with early tumor detection and improved survival; however, it is often underused in clinical practice. We aimed to characterize surveillance use among patients with cirrhosis and the efficacy of interventions to increase surveillance. Approach and Results We performed a systematic literature review using the MEDLINE database from January 2010 through August 2018 to identify cohort studies evaluating HCC surveillance receipt or interventions to increase surveillance in patients with cirrhosis. A pooled estimate for surveillance receipt with 95\% confidence intervals was calculated. Correlates of surveillance use were defined from each study and prespecified subgroup analyses. Twenty-nine studies, with a total of 118,799 patients, met inclusion criteria, with a pooled estimate for surveillance use of 24.0\% (95\% confidence interval, 18.4-30.1). In subgroup analyses, the highest surveillance receipt was reported in studies with patients enrolled from subspecialty gastroenterology/hepatology clinics and lowest in studies characterizing surveillance in population-based cohorts (73.7\% versus 8.8\%, P {\textless} 0.001). Commonly reported correlates of surveillance included higher receipt among patients followed by subspecialists and lower receipt among those with alcohol-associated or nonalcoholic steatohepatitis (NASH)–related cirrhosis. All eight studies (n = 5,229) evaluating interventions including patient/provider education, inreach (e.g., reminder and recall systems), and population health outreach strategies reported significant increases (range 9.4\%-63.6\%) in surveillance receipt. Conclusions HCC surveillance remains underused in clinical practice, particularly among patients with alcohol-associated or NASH-related cirrhosis and those not followed in subspecialty gastroenterology clinics. Interventions such as provider education, inreach including reminder systems, and population health outreach efforts can significantly increase HCC surveillance.},
	language = {en},
	number = {2},
	urldate = {2023-04-07},
	journal = {Hepatology},
	author = {Wolf, Erin and Rich, Nicole E. and Marrero, Jorge A. and Parikh, Neehar D. and Singal, Amit G.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hep.31309},
	pages = {713--725},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/46A4FJDR/Wolf et al. - 2021 - Use of Hepatocellular Carcinoma Surveillance in Pa.pdf:application/pdf;Snapshot:/Users/noltinho/Zotero/storage/XNU7FQVE/hep.html:text/html},
}

@misc{ericksonCancerGenomeAtlas2016,
	title = {The {Cancer} {Genome} {Atlas} {Liver} {Hepatocellular} {Carcinoma} {Collection} ({TCGA}-{LIHC})},
	copyright = {Creative Commons Attribution 3.0 Unported},
	abstract = {The Cancer Genome Atlas Liver Hepatocellular Carcinoma (TCGA-LIHC) data collection is part of a larger effort to build a research community focused on connecting cancer phenotypes to genotypes by providing clinical images matched to subjects from The Cancer Genome Atlas (TCGA). Clinical, genetic, and pathological data resides in the Genomic Data Commons (GDC) Data Portal while the radiological data is stored on The Cancer Imaging Archive (TCIA). Matched TCGA patient identifiers allow researchers to explore the TCGA/TCIA databases for correlations between tissue genotype, radiological phenotype and patient outcomes. Tissues for TCGA were collected from many sites all over the world in order to reach their accrual targets, usually around 500 specimens per cancer type. For this reason the image data sets are also extremely heterogeneous in terms of scanner modalities, manufacturers and acquisition protocols. In most cases the images were acquired as part of routine care and not as part of a controlled research study or clinical trial.},
	publisher = {The Cancer Imaging Archive},
	author = {Erickson, Bradley J. and Kirk, Shanah and Lee, Yueh and Bathe, Oliver and Kearns, Melissa and Gerdes, Cindy and Rieger-Christ, Kimberly and Lemmerman, John},
	year = {2016},
	doi = {10.7937/K9/TCIA.2016.IMMQW8UQ},
}

@article{estesModelingEpidemicNonalcoholic2018,
	title = {Modeling the {Epidemic} of {Nonalcoholic} {Fatty} {Liver} {Disease} {Demonstrates} an {Exponential} {Increase} in {Burden} of {Disease}},
	volume = {67},
	issn = {1527-3350},
	doi = {10.1002/hep.29466},
	abstract = {Nonalcoholic fatty liver disease (NAFLD) and resulting nonalcoholic steatohepatitis (NASH) are highly prevalent in the United States, where they are a growing cause of cirrhosis and hepatocellular carcinoma (HCC) and increasingly an indicator for liver transplantation. A Markov model was used to forecast NAFLD disease progression. Incidence of NAFLD was based on historical and projected changes in adult prevalence of obesity and type 2 diabetes mellitus (DM). Assumptions were derived from published literature where available and validated using national surveillance data for incidence of NAFLD-related HCC. Projected changes in NAFLD-related cirrhosis, advanced liver disease, and liver-related mortality were quantified through 2030. Prevalent NAFLD cases are forecasted to increase 21\%, from 83.1 million (2015) to 100.9 million (2030), while prevalent NASH cases will increase 63\% from 16.52 million to 27.00 million cases. Overall NAFLD prevalence among the adult population (aged {\textbackslash}geq15 years) is projected at 33.5\% in 2030, and the median age of the NAFLD population will increase from 50 to 55 years during 2015-2030. In 2015, approximately 20\% of NAFLD cases were classified as NASH, increasing to 27\% by 2030, a reflection of both disease progression and an aging population. Incidence of decompensated cirrhosis will increase 168\% to 105,430 cases by 2030, while incidence of HCC will increase by 137\% to 12,240 cases. Liver deaths will increase 178\% to an estimated 78,300 deaths in 2030. During 2015-2030, there are projected to be nearly 800,000 excess liver deaths. Conclusion: With continued high rates of adult obesity and DM along with an aging population, NAFLD-related liver disease and mortality will increase in the United States. Strategies to slow the growth of NAFLD cases and therapeutic options are necessary to mitigate disease burden. (Hepatology 2018;67:123-133).},
	number = {1},
	journal = {Hepatology},
	author = {Estes, Chris and Razavi, Homie and Loomba, Rohit and Younossi, Zobair and Sanyal, Arun J.},
	year = {2018},
	pages = {123--133},
}

@article{europeanassociationforthestudyoftheliverEASLClinicalPractice2018,
	title = {{EASL} {Clinical} {Practice} {Guidelines}: {Management} of {Hepatocellular} {Carcinoma}},
	volume = {69},
	issn = {0168-8278},
	shorttitle = {{EASL} {Clinical} {Practice} {Guidelines}},
	doi = {10.1016/j.jhep.2018.03.019},
	abstract = {Liver cancer is the fifth most common cancer and the second most frequent cause of cancer-related death globally. Hepatocellular carcinoma represents about 90\% of primary liver cancers and constitutes a major global health problem. The following Clinical Practice Guidelines will give up-to-date advice for the clinical management of patients with hepatocellular carcinoma, as well as providing an in-depth review of all the relevant data leading to the conclusions herein.},
	number = {1},
	journal = {Journal of Hepatology},
	author = {{European Association For The Study Of The Liver}},
	month = jul,
	year = {2018},
	pages = {182--236},
}

@misc{heDeepResidualLearning2015,
	title = {Deep {Residual} {Learning} for {Image} {Recognition}},
	abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers—8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57\% error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28\% relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC \& COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
	publisher = {arXiv},
	author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	month = dec,
	year = {2015},
	doi = {10.48550/arXiv.1512.03385},
	note = {Issue: arXiv:1512.03385
arXiv: 1512.03385},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@misc{kavurCHAOSCombinedCTMR2019,
	title = {{CHAOS} - {Combined} ({CT}-{MR}) {Healthy} {Abdominal} {Organ} {Segmentation} {Challenge} {Data}},
	abstract = {This is the train and testing dataset of Combined (CT-MR) Healthy Abdominal Organ Segmentation (CHAOS) Challenge. This data consists of images of Abdominal CT and MRI from different patients. There are 20 training and 20 testing cases in the CT dataset. MRI dataset contains 20 training and 20 testing cases with T1-Dual and T2 SPIR sequences. Train data contains both DICOM images and their ground truth masks. The testing set only contains DICOM images. In CT cases only livers were annotated. In MRI cases, livers, left/right kidneys, and spleens were annotated. For further information about the data and challenge, please visit https://chaos.grand-challenge.org/ and read the CHAOS\_Submission\_Manual.pdf Important note: Ground truths/references of the test data are reserved for challenge validation and will never be shared publicly. Such requests will be ignored. Scientists may use this data not only join to the CHAOS challenge but also for other works as long as they give appropriate credit, provide a link to the license, and indicate if changes were made. Bibtex: @dataset\{CHAOSdata2019, author = \{Ali Emre Kavur and M. Alper Selver and Oğuz Dicle and Mustafa Barış and N. Sinem Gezer\}, title = \{\{CHAOS - Combined (CT-MR) Healthy Abdominal Organ Segmentation Challenge Data\}\}, month = Apr, year = 2019, publisher = \{Zenodo\}, version = \{v1.03\}, doi = \{10.5281/zenodo.3362844\}, url = \{https://doi.org/10.5281/zenodo.3362844\} \} IEEE Style: Ali Emre Kavur, M. Alper Selver, Oğuz Dicle, Mustafa Barış, and N. Sinem Gezer, "CHAOS - Combined (CT-MR) Healthy Abdominal Organ Segmentation Challenge Data". Zenodo, 11-Apr-2019. APA Style: Ali Emre Kavur, M. Alper Selver, Oğuz Dicle, Mustafa Barış, \& N. Sinem Gezer. (2019). CHAOS - Combined (CT-MR) Healthy Abdominal Organ Segmentation Challenge Data (Version v1.03) [Data set]. Zenodo. http://doi.org/10.5281/zenodo.3362844},
	publisher = {Zenodo},
	author = {Kavur, Ali Emre and Selver, M. Alper and Dicle, Oğuz and Barış, Mustafa and Gezer, N. Sinem},
	month = apr,
	year = {2019},
	doi = {10.5281/zenodo.3431873},
	keywords = {MRI, Abdomen organs, CT, Kidney, Liver, Spleen},
}

@article{kimTransferLearningMedical2022,
	title = {Transfer {Learning} for {Medical} {Image} {Classification}: {A} {Literature} {Review}},
	volume = {22},
	issn = {1471-2342},
	shorttitle = {Transfer {Learning} for {Medical} {Image} {Classification}},
	doi = {10.1186/s12880-022-00793-7},
	abstract = {Transfer learning (TL) with convolutional neural networks aims to improve performances on a new task by leveraging the knowledge of similar tasks learned in advance. It has made a major contribution to medical image analysis as it overcomes the data scarcity problem as well as it saves time and hardware resources. However, transfer learning has been arbitrarily configured in the majority of studies. This review paper attempts to provide guidance for selecting a model and TL approaches for the medical image classification task.},
	number = {1},
	journal = {BMC Medical Imaging},
	author = {Kim, Hee E. and Cosa-Linan, Alejandro and Santhanam, Nandhini and Jannesari, Mahboubeh and Maros, Mate E. and Ganslandt, Thomas},
	month = apr,
	year = {2022},
	keywords = {Deep learning, Transfer learning, Medical image analysis, Convolutional neural network, Fine-tuning},
	pages = {69},
}

@misc{raghuTransfusionUnderstandingTransfer2019,
	title = {Transfusion: {Understanding} {Transfer} {Learning} for {Medical} {Imaging}},
	shorttitle = {Transfusion},
	abstract = {Transfer learning from natural image datasets, particularly ImageNet, using standard large models and corresponding pretrained weights has become a de-facto method for deep learning applications to medical imaging. However, there are fundamental differences in data sizes, features and task specifications between natural image classification and the target medical tasks, and there is little understanding of the effects of transfer. In this paper, we explore properties of transfer learning for medical imaging. A performance evaluation on two large scale medical imaging tasks shows that surprisingly, transfer offers little benefit to performance, and simple, lightweight models can perform comparably to ImageNet architectures. Investigating the learned representations and features, we find that some of the differences from transfer learning are due to the over-parametrization of standard models rather than sophisticated feature reuse. We isolate where useful feature reuse occurs, and outline the implications for more efficient model exploration. We also explore feature independent benefits of transfer arising from weight scalings.},
	publisher = {arXiv},
	author = {Raghu, Maithra and Zhang, Chiyuan and Kleinberg, Jon and Bengio, Samy},
	month = oct,
	year = {2019},
	doi = {10.48550/arXiv.1902.07208},
	note = {Issue: arXiv:1902.07208
arXiv: 1902.07208},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{breharComparisonDeepLearningConventional2020,
	title = {Comparison of {Deep}-{Learning} and {Conventional} {Machine}-{Learning} {Methods} for the {Automatic} {Recognition} of the {Hepatocellular} {Carcinoma} {Areas} from {Ultrasound} {Images}},
	volume = {20},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {1424-8220},
	url = {https://www.mdpi.com/1424-8220/20/11/3085},
	doi = {10.3390/s20113085},
	abstract = {The emergence of deep-learning methods in different computer vision tasks has proved to offer increased detection, recognition or segmentation accuracy when large annotated image datasets are available. In the case of medical image processing and computer-aided diagnosis within ultrasound images, where the amount of available annotated data is smaller, a natural question arises: are deep-learning methods better than conventional machine-learning methods? How do the conventional machine-learning methods behave in comparison with deep-learning methods on the same dataset? Based on the study of various deep-learning architectures, a lightweight multi-resolution Convolutional Neural Network (CNN) architecture is proposed. It is suitable for differentiating, within ultrasound images, between the Hepatocellular Carcinoma (HCC), respectively the cirrhotic parenchyma (PAR) on which HCC had evolved. The proposed deep-learning model is compared with other CNN architectures that have been adapted by transfer learning for the ultrasound binary classification task, but also with conventional machine-learning (ML) solutions trained on textural features. The achieved results show that the deep-learning approach overcomes classical machine-learning solutions, by providing a higher classification performance.},
	language = {en},
	number = {11},
	urldate = {2023-04-26},
	journal = {Sensors},
	author = {Brehar, Raluca and Mitrea, Delia-Alexandrina and Vancea, Flaviu and Marita, Tiberiu and Nedevschi, Sergiu and Lupsor-Platon, Monica and Rotaru, Magda and Badea, Radu Ioan},
	month = jan,
	year = {2020},
	note = {Number: 11
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {automatic diagnosis, Convolutional Neural Networks (CNN), Hepatocellular Carcinoma (HCC), image processing, pattern recognition, ultrasound images},
	pages = {3085},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/CRT8SKSX/Brehar et al. - 2020 - Comparison of Deep-Learning and Conventional Machi.pdf:application/pdf},
}

@article{schmauchDiagnosisFocalLiver2019,
	title = {Diagnosis of focal liver lesions from ultrasound using deep learning},
	volume = {100},
	issn = {2211-5684},
	url = {https://www.sciencedirect.com/science/article/pii/S2211568419300592},
	doi = {10.1016/j.diii.2019.02.009},
	abstract = {Purpose
The purpose of this study was to create an algorithm that simultaneously detects and characterizes (benign vs. malignant) focal liver lesion (FLL) using deep learning.
Materials and methods
We trained our algorithm on a dataset proposed during a data challenge organized at the 2018 Journées Francophones de Radiologie. The dataset was composed of 367 two-dimensional ultrasound images from 367 individual livers, captured at various institutions. The algorithm was guided using an attention mechanism with annotations made by a radiologist. The algorithm was then tested on a new data set from 177 patients.
Results
The models reached mean ROC-AUC scores of 0.935 for FLL detection and 0.916 for FLL characterization over three shuffled three-fold cross-validations performed with the training data. On the new dataset of 177 patients, our models reached a weighted mean ROC-AUC scores of 0.891 for seven different tasks.
Conclusion
This study that uses a supervised-attention mechanism focused on FLL detection and characterization from liver ultrasound images. This method could prove to be highly relevant for medical imaging once validated on a larger independent cohort.},
	language = {en},
	number = {4},
	urldate = {2023-04-26},
	journal = {Diagnostic and Interventional Imaging},
	author = {Schmauch, B. and Herent, P. and Jehanno, P. and Dehaene, O. and Saillard, C. and Aubé, C. and Luciani, A. and Lassau, N. and Jégou, S.},
	month = apr,
	year = {2019},
	keywords = {Artificial intelligence, Deep learning, Ultrasound, Focal liver lesions, Radiology},
	pages = {227--233},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/X6RY7S9Q/Schmauch et al. - 2019 - Diagnosis of focal liver lesions from ultrasound u.pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/V88C3T84/S2211568419300592.html:text/html},
}

@article{yangImprovingBmodeUltrasound2020,
	title = {Improving {B}-mode ultrasound diagnostic performance for focal liver lesions using deep learning: {A} multicentre study},
	volume = {56},
	issn = {2352-3964},
	shorttitle = {Improving {B}-mode ultrasound diagnostic performance for focal liver lesions using deep learning},
	url = {https://www.sciencedirect.com/science/article/pii/S2352396420301523},
	doi = {10.1016/j.ebiom.2020.102777},
	abstract = {Background
The diagnosis performance of B-mode ultrasound (US) for focal liver lesions (FLLs) is relatively limited. We aimed to develop a deep convolutional neural network of US (DCNN-US) for aiding radiologists in classification of malignant from benign FLLs.
Materials and methods
This study was conducted in 13 hospitals and finally 2143 patients with 24,343 US images were enrolled. Patients who had non-cystic FLLs with pathological results were enrolled. The FLLs from 11 hospitals were randomly divided into training and internal validations (IV) cohorts with a 4:1 ratio for developing and evaluating DCNN-US. Diagnostic performance of the model was verified using external validation (EV) cohort from another two hospitals. The diagnosis value of DCNN-US was compared with that of contrast enhanced computed tomography (CT)/magnetic resonance image (MRI) and 236 radiologists, respectively.
Findings
The AUC of ModelLBC for FLLs was 0.924 (95\% CI: 0.889–0.959) in the EV cohort. The diagnostic sensitivity and specificity of ModelLBC were superior to 15-year skilled radiologists (86.5\% vs 76.1\%, p = 0.0084 and 85.5\% vs 76.9\%, p = 0.0051, respectively). Accuracy of ModelLBC was comparable to that of contrast enhanced CT (both 84.7\%) but inferior to contrast enhanced MRI (87.9\%) for lesions detected by US.
Interpretation
DCNN-US with high sensitivity and specificity in diagnosing FLLs shows its potential to assist less-experienced radiologists in improving their performance and lowering their dependence on sectional imaging in liver cancer diagnosis.},
	language = {en},
	urldate = {2023-04-26},
	journal = {EBioMedicine},
	author = {Yang, Qi and Wei, Jingwei and Hao, Xiaohan and Kong, Dexing and Yu, Xiaoling and Jiang, Tianan and Xi, Junqing and Cai, Wenjia and Luo, Yanchun and Jing, Xiang and Yang, Yilin and Cheng, Zhigang and Wu, Jinyu and Zhang, Huiping and Liao, Jintang and Zhou, Pei and Song, Yu and Zhang, Yao and Han, Zhiyu and Cheng, Wen and Tang, Lina and Liu, Fangyi and Dou, Jianping and Zheng, Rongqin and Yu, Jie and Tian, Jie and Liang, Ping},
	month = jun,
	year = {2020},
	keywords = {Diagnosis, Ultrasound, Convolutional neural network, Focal liver lesions},
	pages = {102777},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/G36Q7JXM/Yang et al. - 2020 - Improving B-mode ultrasound diagnostic performance.pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/BKMNH4R4/S2352396420301523.html:text/html},
}

@article{yasakaDeepLearningConvolutional2018a,
	title = {Deep {Learning} with {Convolutional} {Neural} {Network} for {Differentiation}                    of {Liver} {Masses} at {Dynamic} {Contrast}-enhanced {CT}: {A} {Preliminary}                    {Study}},
	volume = {286},
	issn = {0033-8419},
	shorttitle = {Deep {Learning} with {Convolutional} {Neural} {Network} for {Differentiation}                    of {Liver} {Masses} at {Dynamic} {Contrast}-enhanced {CT}},
	url = {https://pubs.rsna.org/doi/full/10.1148/radiol.2017170706},
	doi = {10.1148/radiol.2017170706},
	abstract = {Purpose

To investigate diagnostic performance by using a deep learning method with a convolutional neural network (CNN) for the differentiation of liver masses at dynamic contrast agent–enhanced computed tomography (CT).

Materials and Methods

This clinical retrospective study used CT image sets of liver masses over three phases (noncontrast-agent enhanced, arterial, and delayed). Masses were diagnosed according to five categories (category A, classic hepatocellular carcinomas [HCCs]; category B, malignant liver tumors other than classic and early HCCs; category C, indeterminate masses or mass-like lesions [including early HCCs and dysplastic nodules] and rare benign liver masses other than hemangiomas and cysts; category D, hemangiomas; and category E, cysts). Supervised training was performed by using 55 536 image sets obtained in 2013 (from 460 patients, 1068 sets were obtained and they were augmented by a factor of 52 [rotated, parallel-shifted, strongly enlarged, and noise-added images were generated from the original images]). The CNN was composed of six convolutional, three maximum pooling, and three fully connected layers. The CNN was tested with 100 liver mass image sets obtained in 2016 (74 men and 26 women; mean age, 66.4 years ± 10.6 [standard deviation]; mean mass size, 26.9 mm ± 25.9; 21, nine, 35, 20, and 15 liver masses for categories A, B, C, D, and E, respectively). Training and testing were performed five times. Accuracy for categorizing liver masses with CNN model and the area under receiver operating characteristic curve for differentiating categories A–B versus categories C–E were calculated.

Results

Median accuracy of differential diagnosis of liver masses for test data were 0.84. Median area under the receiver operating characteristic curve for differentiating categories A–B from C–E was 0.92.

Conclusion

Deep learning with CNN showed high diagnostic performance in differentiation of liver masses at dynamic CT.

© RSNA, 2017

Online supplemental material is available for this article.},
	number = {3},
	urldate = {2023-04-26},
	journal = {Radiology},
	author = {Yasaka, Koichiro and Akai, Hiroyuki and Abe, Osamu and Kiryu, Shigeru},
	month = mar,
	year = {2018},
	note = {Publisher: Radiological Society of North America},
	pages = {887--896},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/3IL8DB8T/Yasaka et al. - 2018 - Deep Learning with Convolutional Neural Network fo.pdf:application/pdf},
}

@inproceedings{todorokiAutomaticDetectionFocal2019,
	title = {Automatic {Detection} of {Focal} {Liver} {Lesions} in {Multi}-phase {CT} {Images} {Using} {A} {Multi}-channel \& {Multi}-scale {CNN}},
	doi = {10.1109/EMBC.2019.8857292},
	abstract = {There are multiple types of tumors occurring in the liver, each of which have a different visual appearance that changes after injection of the contrast medium. Therefore, detection of liver tumors is considered to be a challenging task.In the present article, the authors propose a method for detection of liver tumor candidates with different size in multiphase CT images using a multi-channel and multi-scale CNN protocol. Experimental results demonstrated that recall scores and dice coefficient can be significantly improved, with a reduction in the number of average false positives using the proposed method compared with existing methods.},
	booktitle = {2019 41st {Annual} {International} {Conference} of the {IEEE} {Engineering} in {Medicine} and {Biology} {Society} ({EMBC})},
	author = {Todoroki, Yoshihiro and Iwamoto, Yutaro and Lin, Lanfen and Hu, Hongjie and Chen, Yen-Wei},
	month = jul,
	year = {2019},
	note = {ISSN: 1558-4615},
	keywords = {Computed tomography, Liver, Frequency locked loops, Lesions, Protocols, Subspace constraints},
	pages = {872--875},
	file = {IEEE Xplore Abstract Record:/Users/noltinho/Zotero/storage/FZBM7L9Z/8857292.html:text/html;IEEE Xplore Full Text PDF:/Users/noltinho/Zotero/storage/KAXDEXFR/Todoroki et al. - 2019 - Automatic Detection of Focal Liver Lesions in Mult.pdf:application/pdf},
}

@article{shiDeepLearningAssisted2020,
	title = {Deep learning assisted differentiation of hepatocellular carcinoma from focal liver lesions: choice of four-phase and three-phase {CT} imaging protocol},
	volume = {45},
	issn = {2366-0058},
	shorttitle = {Deep learning assisted differentiation of hepatocellular carcinoma from focal liver lesions},
	url = {https://doi.org/10.1007/s00261-020-02485-8},
	doi = {10.1007/s00261-020-02485-8},
	abstract = {To evaluate whether a three-phase dynamic contrast-enhanced CT protocol, when combined with a deep learning model, has similar accuracy in differentiating hepatocellular carcinoma (HCC) from other focal liver lesions (FLLs) compared with a four-phase protocol.},
	language = {en},
	number = {9},
	urldate = {2023-04-26},
	journal = {Abdominal Radiology},
	author = {Shi, Wenqi and Kuang, Sichi and Cao, Sue and Hu, Bing and Xie, Sidong and Chen, Simin and Chen, Yinan and Gao, Dashan and Chen, Yunqiang and Zhu, Yajing and Zhang, Hanxi and Liu, Hui and Ye, Meng and Sirlin, Claude B. and Wang, Jin},
	month = sep,
	year = {2020},
	keywords = {Artificial intelligence, Deep learning, Hepatocellular carcinoma, Computed tomography (CT), Differential diagnosis, Radiation dosage},
	pages = {2688--2697},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/JIXFC2LC/Shi et al. - 2020 - Deep learning assisted differentiation of hepatoce.pdf:application/pdf},
}

@article{zhouAutomaticDetectionClassification2021,
	title = {Automatic {Detection} and {Classification} of {Focal} {Liver} {Lesions} {Based} on {Deep} {Convolutional} {Neural} {Networks}: {A} {Preliminary} {Study}},
	volume = {10},
	issn = {2234-943X},
	shorttitle = {Automatic {Detection} and {Classification} of {Focal} {Liver} {Lesions} {Based} on {Deep} {Convolutional} {Neural} {Networks}},
	url = {https://www.frontiersin.org/articles/10.3389/fonc.2020.581210},
	abstract = {With the increasing daily workload of physicians, computer-aided diagnosis (CAD) systems based on deep learning play an increasingly important role in pattern recognition of diagnostic medical images. In this paper, we propose a framework based on hierarchical convolutional neural networks (CNNs) for automatic detection and classification of focal liver lesions (FLLs) in multi-phasic computed tomography (CT). A total of 616 nodules, composed of three types of malignant lesions (hepatocellular carcinoma, intrahepatic cholangiocarcinoma, and metastasis) and benign lesions (hemangioma, focal nodular hyperplasia, and cyst), were randomly divided into training and test sets at an approximate ratio of 3:1. To evaluate the performance of our model, other commonly adopted CNN models and two physicians were included for comparison. Our model achieved the best results to detect FLLs, with an average test precision of 82.8\%, recall of 93.4\%, and F1-score of 87.8\%. Our model initially classified FLLs into malignant and benign and then classified them into more detailed classes. For the binary and six-class classification, our model achieved average accuracy results of 82.5 and73.4\%, respectively, which were better than the other three classification neural networks. Interestingly, the classification performance of the model was placed between a junior physician and a senior physician. Overall, this preliminary study demonstrates that our proposed multi-modality and multi-scale CNN structure can locate and classify FLLs accurately in a limited dataset, and would help inexperienced physicians to reach a diagnosis in clinical practice.},
	urldate = {2023-04-26},
	journal = {Frontiers in Oncology},
	author = {Zhou, Jiarong and Wang, Wenzhe and Lei, Biwen and Ge, Wenhao and Huang, Yu and Zhang, Linshi and Yan, Yingcai and Zhou, Dongkai and Ding, Yuan and Wu, Jian and Wang, Weilin},
	year = {2021},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/GFA4VBQ3/Zhou et al. - 2021 - Automatic Detection and Classification of Focal Li.pdf:application/pdf},
}

@article{ponnopratClassificationHepatocellularCarcinoma2020,
	title = {Classification of hepatocellular carcinoma and intrahepatic cholangiocarcinoma based on multi-phase {CT} scans},
	volume = {58},
	issn = {1741-0444},
	url = {https://doi.org/10.1007/s11517-020-02229-2},
	doi = {10.1007/s11517-020-02229-2},
	abstract = {Liver and bile duct cancers are leading causes of worldwide cancer death. The most common ones are hepatocellular carcinoma (HCC) and intrahepatic cholangiocarcinoma (ICC). Influencing factors and prognosis of HCC and ICC are different. Precise classification of these two liver cancers is essential for treatment and prevention plans. The aim of this study is to develop a machine-based method that differentiates between the two types of liver cancers from multi-phase abdominal computerized tomography (CT) scans. The proposed method consists of two major steps. In the first step, the liver is segmented from the original images using a convolutional neural network model, together with task-specific pre-processing and post-processing techniques. In the second step, by looking at the intensity histograms of the segmented images, we extract features from regions that are discriminating between HCC and ICC, and use them as an input for classification using support vector machine model. By testing on a dataset of labeled multi-phase CT scans provided by Maharaj Nakorn Chiang Mai Hospital, Thailand, we have obtained 88\% in classification accuracy. Our proposed method has a great potential in helping radiologists diagnosing liver cancer.},
	language = {en},
	number = {10},
	urldate = {2023-04-26},
	journal = {Medical \& Biological Engineering \& Computing},
	author = {Ponnoprat, Donlapark and Inkeaw, Papangkorn and Chaijaruwanich, Jeerayut and Traisathit, Patrinee and Sripan, Patumrat and Inmutto, Nakarin and Na Chiangmai, Wittanee and Pongnikorn, Donsuk and Chitapanarux, Imjai},
	month = oct,
	year = {2020},
	keywords = {Machine learning, Classification, Image processing, Liver neoplasms, Tomography},
	pages = {2497--2515},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/SFH453XH/Ponnoprat et al. - 2020 - Classification of hepatocellular carcinoma and int.pdf:application/pdf},
}

@article{liFullyAutomaticComputeraided2020,
	title = {A fully automatic computer-aided diagnosis system for hepatocellular carcinoma using convolutional neural networks},
	volume = {40},
	issn = {0208-5216},
	url = {https://www.sciencedirect.com/science/article/pii/S0208521619300658},
	doi = {10.1016/j.bbe.2019.05.008},
	abstract = {The cancer of liver, which is the leading cause of cancer death, is commonly diagnosed by comparing the changes of gray level of liver tissue in the different phases of the patient's CT images. To aid the doctor in reducing misdiagnosis or missed diagnosis, a fully automatic computer-aided diagnosis (CAD) system is proposed to diagnose hepatocellular carcinoma (HCC) using convolutional neural network (CNN) classifier. The automatic segmentation and classification are two core technologies of the proposed CAD system, which are both realized based on CNN. The segmentation of liver and tumor is implemented by a fully convolutional networks (FCN) based on a fine tuning VGG-16 model with two additional ‘skip structures’ using a weighted loss function which helps to solve the problem of inaccurate tumor segmentation caused by the inevitably unbalanced training data. HCC classification is implemented by a 9-layer CNN classifier, whose input is a 4-channel image data constructed by combining the segmentation result of FCN with the original CT image. A total of 165 venous phase CT images including 46 diffuse tumors, 43 nodular tumors, and 76 massive tumors are used to evaluate the performance of the proposed CAD system. The classification accuracy of CNN classifier for diffuse, nodular and massive tumors are 98.4\%, 99.7\% and 98.7\% respectively, which are significantly improved in contrast with the traditional feature-based ANN and SVM classifiers. The proposed CAD system, which is unaffected by the difference of preprocessing method and feature type, is proved satisfactory and feasible by the test set.},
	language = {en},
	number = {1},
	urldate = {2023-04-26},
	journal = {Biocybernetics and Biomedical Engineering},
	author = {Li, Jing and Wu, Yurun and Shen, Nanyan and Zhang, Jiawen and Chen, Enlong and Sun, Jie and Deng, Zongqian and Zhang, Yuchen},
	month = jan,
	year = {2020},
	keywords = {Hepatocellular carcinoma, Fully convolutional networks, Liver segmentation, Venous phase, Weighted loss function},
	pages = {238--248},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/QG3ZC8Y4/Li et al. - 2020 - A fully automatic computer-aided diagnosis system .pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/R453HRS9/S0208521619300658.html:text/html},
}

@article{hammDeepLearningLiver2019a,
	title = {Deep learning for liver tumor diagnosis part {I}: development of a convolutional neural network classifier for multi-phasic {MRI}},
	volume = {29},
	issn = {1432-1084},
	shorttitle = {Deep learning for liver tumor diagnosis part {I}},
	url = {https://doi.org/10.1007/s00330-019-06205-9},
	doi = {10.1007/s00330-019-06205-9},
	abstract = {To develop and validate a proof-of-concept convolutional neural network (CNN)–based deep learning system (DLS) that classifies common hepatic lesions on multi-phasic MRI.},
	language = {en},
	number = {7},
	urldate = {2023-04-26},
	journal = {European Radiology},
	author = {Hamm, Charlie A. and Wang, Clinton J. and Savic, Lynn J. and Ferrante, Marc and Schobert, Isabel and Schlachter, Todd and Lin, MingDe and Duncan, James S. and Weinreb, Jeffrey C. and Chapiro, Julius and Letzen, Brian},
	month = jul,
	year = {2019},
	keywords = {Artificial intelligence, Deep learning, Liver cancer},
	pages = {3338--3347},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/EEBHAP54/Hamm et al. - 2019 - Deep learning for liver tumor diagnosis part I de.pdf:application/pdf},
}

@article{oestmannDeepLearningAssisted2021,
	title = {Deep learning–assisted differentiation of pathologically proven atypical and typical hepatocellular carcinoma ({HCC}) versus non-{HCC} on contrast-enhanced {MRI} of the liver},
	volume = {31},
	issn = {1432-1084},
	url = {https://doi.org/10.1007/s00330-020-07559-1},
	doi = {10.1007/s00330-020-07559-1},
	abstract = {To train a deep learning model to differentiate between pathologically proven hepatocellular carcinoma (HCC) and non-HCC lesions including lesions with atypical imaging features on MRI.},
	language = {en},
	number = {7},
	urldate = {2023-04-26},
	journal = {European Radiology},
	author = {Oestmann, Paula M. and Wang, Clinton J. and Savic, Lynn J. and Hamm, Charlie A. and Stark, Sophie and Schobert, Isabel and Gebauer, Bernhard and Schlachter, Todd and Lin, MingDe and Weinreb, Jeffrey C. and Batra, Ramesh and Mulligan, David and Zhang, Xuchen and Duncan, James S. and Chapiro, Julius},
	month = jul,
	year = {2021},
	keywords = {Deep learning, Magnetic resonance imaging, Liver neoplasms, Carcinoma, hepatocellular, Neural networks, computer},
	pages = {4981--4990},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/RPSYEVEN/Oestmann et al. - 2021 - Deep learning–assisted differentiation of patholog.pdf:application/pdf},
}

@article{wuDeepLearningLIRADS2020a,
	title = {Deep learning {LI}-{RADS} grading system based on contrast enhanced multiphase {MRI} for differentiation between {LR}-3 and {LR}-4/{LR}-5 liver tumors},
	volume = {8},
	issn = {2305-5839},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7327307/},
	doi = {10.21037/atm.2019.12.151},
	abstract = {Background
To develop a deep learning (DL) method based on multiphase, contrast-enhanced (CE) magnetic resonance imaging (MRI) to distinguish Liver Imaging Reporting and Data System (LI-RADS) grade 3 (LR-3) liver tumors from combined higher-grades 4 and 5 (LR-4/LR-5) tumors for hepatocellular carcinoma (HCC) diagnosis.

Methods
A total of 89 untreated LI-RADS-graded liver tumors (35 LR-3, 14 LR-4, and 40 LR-5) were identified based on the radiology MRI interpretation reports. Multiphase 3D T1-weighted gradient echo imaging was acquired at six time points: pre-contrast, four phases immediately post-contrast, and one hepatobiliary phase after intravenous injection of gadoxetate disodium. Image co-registration was performed across all phases on the center tumor slice to correct motion. A rectangular tumor box centered on the tumor area was drawn to extract subset tumor images for each imaging phase, which were used as the inputs to a convolutional neural network (CNN). The pre-trained AlexNet CNN model underwent transfer learning using liver MRI data for LI-RADS tumor grade classification. The output probability number closer to 1 or 0 indicated a higher possibility of being combined LR-4/LR-5 tumor or LR-3 tumor, respectively. Five-fold cross validation was used for training (60\% dataset), validation (20\%) and testing processes (20\%).

Results
The DL CNN model for LI-RADS grading using inputs of multiphase liver MRI data acquired at three time points (pre-contrast, arterial, and washout phase) achieved a high accuracy of 0.90, sensitivity of 1.0, precision of 0.835, and AUC of 0.95 with reference to the expert human radiologist report. The CNN output of probability provided radiologists a confidence level of the model’s grading for each liver lesion.

Conclusions
An AlexNet CNN model for LI-RADS grading of liver lesions provided diagnostic performance comparable to radiologists and offered valuable clinical guidance for differentiating intermediate LR-3 liver lesions from more-likely malignant LR-4/LR-5 lesions in HCC diagnosis.},
	number = {11},
	urldate = {2023-04-26},
	journal = {Annals of Translational Medicine},
	author = {Wu, Yunan and White, Gregory M. and Cornelius, Tyler and Gowdar, Indraneel and Ansari, Mohammad H. and Supanich, Mark P. and Deng, Jie},
	month = jun,
	year = {2020},
	pmid = {32617321},
	pmcid = {PMC7327307},
	pages = {701},
	file = {PubMed Central Full Text PDF:/Users/noltinho/Zotero/storage/9T3FXHVW/Wu et al. - 2020 - Deep learning LI-RADS grading system based on cont.pdf:application/pdf},
}

@article{zhenDeepLearningAccurate2020b,
	title = {Deep {Learning} for {Accurate} {Diagnosis} of {Liver} {Tumor} {Based} on {Magnetic} {Resonance} {Imaging} and {Clinical} {Data}},
	volume = {10},
	issn = {2234-943X},
	url = {https://www.frontiersin.org/articles/10.3389/fonc.2020.00680},
	abstract = {Background: Early-stage diagnosis and treatment can improve survival rates of liver cancer patients. Dynamic contrast-enhanced MRI provides the most comprehensive information for differential diagnosis of liver tumors. However, MRI diagnosis is affected by subjective experience, so deep learning may supply a new diagnostic strategy. We used convolutional neural networks (CNNs) to develop a deep learning system (DLS) to classify liver tumors based on enhanced MR images, unenhanced MR images, and clinical data including text and laboratory test results.Methods: Using data from 1,210 patients with liver tumors (N = 31,608 images), we trained CNNs to get seven-way classifiers, binary classifiers, and three-way malignancy-classifiers (Model A-Model G). Models were validated in an external independent extended cohort of 201 patients (N = 6,816 images). The area under receiver operating characteristic (ROC) curve (AUC) were compared across different models. We also compared the sensitivity and specificity of models with the performance of three experienced radiologists.Results: Deep learning achieves a performance on par with three experienced radiologists on classifying liver tumors in seven categories. Using only unenhanced images, CNN performs well in distinguishing malignant from benign liver tumors (AUC, 0.946; 95\% CI 0.914–0.979 vs. 0.951; 0.919–0.982, P = 0.664). New CNN combining unenhanced images with clinical data greatly improved the performance of classifying malignancies as hepatocellular carcinoma (AUC, 0.985; 95\% CI 0.960–1.000), metastatic tumors (0.998; 0.989–1.000), and other primary malignancies (0.963; 0.896–1.000), and the agreement with pathology was 91.9\%.These models mined diagnostic information in unenhanced images and clinical data by deep-neural-network, which were different to previous methods that utilized enhanced images. The sensitivity and specificity of almost every category in these models reached the same high level compared to three experienced radiologists.Conclusion: Trained with data in various acquisition conditions, DLS that integrated these models could be used as an accurate and time-saving assisted-diagnostic strategy for liver tumors in clinical settings, even in the absence of contrast agents. DLS therefore has the potential to avoid contrast-related side effects and reduce economic costs associated with current standard MRI inspection practices for liver tumor patients.},
	urldate = {2023-04-26},
	journal = {Frontiers in Oncology},
	author = {Zhen, Shi-hui and Cheng, Ming and Tao, Yu-bo and Wang, Yi-fan and Juengpanich, Sarun and Jiang, Zhi-yu and Jiang, Yan-kai and Yan, Yu-yu and Lu, Wei and Lue, Jie-min and Qian, Jia-hong and Wu, Zhong-yu and Sun, Ji-hong and Lin, Hai and Cai, Xiu-jun},
	year = {2020},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/ZCTBBFJU/Zhen et al. - 2020 - Deep Learning for Accurate Diagnosis of Liver Tumo.pdf:application/pdf},
}

@inproceedings{mikolajczykDataAugmentationImproving2018,
	title = {Data augmentation for improving deep learning in image classification problem},
	doi = {10.1109/IIPHDW.2018.8388338},
	abstract = {These days deep learning is the fastest-growing field in the field of Machine Learning (ML) and Deep Neural Networks (DNN). Among many of DNN structures, the Convolutional Neural Networks (CNN) are currently the main tool used for the image analysis and classification purposes. Although great achievements and perspectives, deep neural networks and accompanying learning algorithms have some relevant challenges to tackle. In this paper, we have focused on the most frequently mentioned problem in the field of machine learning, that is the lack of sufficient amount of the training data or uneven class balance within the datasets. One of the ways of dealing with this problem is so called data augmentation. In the paper we have compared and analyzed multiple methods of data augmentation in the task of image classification, starting from classical image transformations like rotating, cropping, zooming, histogram based methods and finishing at Style Transfer and Generative Adversarial Networks, along with the representative examples. Next, we presented our own method of data augmentation based on image style transfer. The method allows to generate the new images of high perceptual quality that combine the content of a base image with the appearance of another ones. The newly created images can be used to pre-train the given neural network in order to improve the training process efficiency. Proposed method is validated on the three medical case studies: skin melanomas diagnosis, histopathological images and breast magnetic resonance imaging (MRI) scans analysis, utilizing the image classification in order to provide a diagnose. In such kind of problems the data deficiency is one of the most relevant issues. Finally, we discuss the advantages and disadvantages of the methods being analyzed.},
	booktitle = {2018 {International} {Interdisciplinary} {PhD} {Workshop} ({IIPhDW})},
	author = {Mikołajczyk, Agnieszka and Grochowski, Michał},
	month = may,
	year = {2018},
	keywords = {Machine learning, deep learning, Image classification, Cancer, Lesions, data augmentation, Image color analysis, medical imaging, Neural networks, style transfer, Task analysis},
	pages = {117--122},
	file = {IEEE Xplore Abstract Record:/Users/noltinho/Zotero/storage/ZTYYWCB2/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/noltinho/Zotero/storage/Q6YSDIJ2/Mikołajczyk and Grochowski - 2018 - Data augmentation for improving deep learning in i.pdf:application/pdf},
}

@article{haixiangLearningClassimbalancedData2017,
	title = {Learning from class-imbalanced data: {Review} of methods and applications},
	volume = {73},
	issn = {0957-4174},
	shorttitle = {Learning from class-imbalanced data},
	url = {https://www.sciencedirect.com/science/article/pii/S0957417416307175},
	doi = {10.1016/j.eswa.2016.12.035},
	abstract = {Rare events, especially those that could potentially negatively impact society, often require humans’ decision-making responses. Detecting rare events can be viewed as a prediction task in data mining and machine learning communities. As these events are rarely observed in daily life, the prediction task suffers from a lack of balanced data. In this paper, we provide an in depth review of rare event detection from an imbalanced learning perspective. Five hundred and seventeen related papers that have been published in the past decade were collected for the study. The initial statistics suggested that rare events detection and imbalanced learning are concerned across a wide range of research areas from management science to engineering. We reviewed all collected papers from both a technical and a practical point of view. Modeling methods discussed include techniques such as data preprocessing, classification algorithms and model evaluation. For applications, we first provide a comprehensive taxonomy of the existing application domains of imbalanced learning, and then we detail the applications for each category. Finally, some suggestions from the reviewed papers are incorporated with our experiences and judgments to offer further research directions for the imbalanced learning and rare event detection fields.},
	language = {en},
	urldate = {2023-04-26},
	journal = {Expert Systems with Applications},
	author = {Haixiang, Guo and Yijing, Li and Shang, Jennifer and Mingyun, Gu and Yuanyue, Huang and Bing, Gong},
	month = may,
	year = {2017},
	keywords = {Machine learning, Data mining, Imbalanced data, Rare events},
	pages = {220--239},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/BQ7X9RUF/Haixiang et al. - 2017 - Learning from class-imbalanced data Review of met.pdf:application/pdf},
}

@article{briaAddressingClassImbalance2020,
	title = {Addressing class imbalance in deep learning for small lesion detection on medical images},
	volume = {120},
	issn = {0010-4825},
	url = {https://www.sciencedirect.com/science/article/pii/S0010482520301177},
	doi = {10.1016/j.compbiomed.2020.103735},
	abstract = {Deep learning methods utilizing Convolutional Neural Networks (CNNs) have led to dramatic advances in automated understanding of medical images. However, in many medical image classification tasks, lesions occupy only a few pixels of the image. This results in a significant class imbalance between lesion and background. From recent literature, it is known that class imbalance may negatively affect the performance of CNN classification. However, very few research exists in the context of lesion detection. In this work, we propose a two-stage deep learning framework able to deal with the high class imbalance encountered during training of small lesion detectors. First, we train a deep cascade (DC) of long sequences of decision trees with an algorithm designed to handle unbalanced data that also drastically reduces the number of background samples reaching the final stage. The remaining samples are fed to a CNN, whose training benefits from both rebalance and hard mining done by the DC. We evaluated DC-CNN on two severely unbalanced classification problems: microcalcification detection and microaneurysm detection. In both cases, DC-CNN outperformed the CNNs trained with commonly used methods for addressing class imbalance such as oversampling, undersampling, hard mining, cost sensitive learning, and one-class classification. The DC-CNN was also ∼ 10x faster than CNN at test time.},
	language = {en},
	urldate = {2023-04-26},
	journal = {Computers in Biology and Medicine},
	author = {Bria, Alessandro and Marrocco, Claudio and Tortorella, Francesco},
	month = may,
	year = {2020},
	keywords = {Deep learning, Class imbalance, Lesion detection, Microaneurysms, Microcalcifications},
	pages = {103735},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/6MSWY2ZT/Bria et al. - 2020 - Addressing class imbalance in deep learning for sm.pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/4I52H7C3/S0010482520301177.html:text/html},
}

@misc{liPyTorchDistributedExperiences2020,
	title = {{PyTorch} {Distributed}: {Experiences} on {Accelerating} {Data} {Parallel} {Training}},
	shorttitle = {{PyTorch} {Distributed}},
	url = {http://arxiv.org/abs/2006.15704},
	abstract = {This paper presents the design, implementation, and evaluation of the PyTorch distributed data parallel module. PyTorch is a widely-adopted scientific computing package used in deep learning research and applications. Recent advances in deep learning argue for the value of large datasets and large models, which necessitates the ability to scale out model training to more computational resources. Data parallelism has emerged as a popular solution for distributed training thanks to its straightforward principle and broad applicability. In general, the technique of distributed data parallelism replicates the model on every computational resource to generate gradients independently and then communicates those gradients at each iteration to keep model replicas consistent. Despite the conceptual simplicity of the technique, the subtle dependencies between computation and communication make it non-trivial to optimize the distributed training efficiency. As of v1.5, PyTorch natively provides several techniques to accelerate distributed data parallel, including bucketing gradients, overlapping computation with communication, and skipping gradient synchronization. Evaluations show that, when configured appropriately, the PyTorch distributed data parallel module attains near-linear scalability using 256 GPUs.},
	urldate = {2023-04-26},
	publisher = {arXiv},
	author = {Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li, Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and Chintala, Soumith},
	month = jun,
	year = {2020},
	note = {arXiv:2006.15704 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Distributed, Parallel, and Cluster Computing},
	annote = {Comment: To appear in VLDB 2020},
	file = {arXiv Fulltext PDF:/Users/noltinho/Zotero/storage/X8799QTA/Li et al. - 2020 - PyTorch Distributed Experiences on Accelerating D.pdf:application/pdf;arXiv.org Snapshot:/Users/noltinho/Zotero/storage/7TCUZFN5/2006.html:text/html},
}

@inproceedings{hermansAccumulatedGradientNormalization2017,
	title = {Accumulated {Gradient} {Normalization}},
	url = {https://proceedings.mlr.press/v77/hermans17a.html},
	abstract = {This work addresses the instability in asynchronous data parallel optimization. It does so by introducing a novel distributed optimizer which is able to efficiently optimize a centralized model under communication constraints. The optimizer achieves this by pushing a normalized sequence of first-order gradients to a parameter server. This implies that the magnitude of a worker delta is smaller compared to an accumulated gradient, and provides a better direction towards a minimum compared to first-order gradients, which in turn also forces possible implicit momentum fluctuations to be more aligned since we make the assumption that all workers contribute towards a single minima. As a result, our approach mitigates the parameter staleness problem more effectively since staleness in asynchrony induces (implicit) momentum, and achieves a better convergence rate compared to other optimizers such as asynchronous {\textbackslash}textsceasgd and {\textbackslash}textscdynsgd, which we show empirically.},
	language = {en},
	urldate = {2023-04-26},
	booktitle = {Proceedings of the {Ninth} {Asian} {Conference} on {Machine} {Learning}},
	publisher = {PMLR},
	author = {Hermans, Joeri R. and Spanakis, Gerasimos and Möckel, Rico},
	month = nov,
	year = {2017},
	note = {ISSN: 2640-3498},
	pages = {439--454},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/3HB5QWH2/Hermans et al. - 2017 - Accumulated Gradient Normalization.pdf:application/pdf},
}

@article{yehGenderDisparityHepatocellular2010,
	title = {Gender disparity of hepatocellular carcinoma: the roles of sex hormones},
	volume = {78 Suppl 1},
	issn = {1423-0232},
	shorttitle = {Gender disparity of hepatocellular carcinoma},
	doi = {10.1159/000315247},
	abstract = {Men have a higher incidence of hepatocellular carcinoma (HCC) than women. Epidemiologic and animal studies have suggested that it might be due to the stimulatory effects of androgen and the protective effects of estrogen. Recently, increasing molecular mechanisms underlying the carcinogenic effect of both sex hormones were reported. Knockout of androgen receptor (AR) expression in hepatocytes delayed the development of N',N'-diethylnitrosamine (DEN)-induced HCC, suggesting the active AR pathway in augmenting the HCC risk. Moreover, an intriguing interaction between the viral protein of hepatitis B virus X protein (HBx) and the androgen pathway was established. HBx can enhance the transcriptional activity of AR in a ligand concentration-dependent manner, mainly through its effects on the c-Src and GSK-3beta kinase pathways. The studies from the DEN-induced HCC mouse model further provided a mechanism for the protective role of estrogen in female HCC. Estrogen can protect hepatocytes from malignant transformation via downregulation of IL-6 release from Kupffer cells, a critical process in this mouse model. Intriguingly, suppression of the ERalpha protein by overexpression of miR-18a, which occurs preferentially in female HCC, was identified as a novel mechanism to block the tumor-protective function of estrogen in female HCC. In conclusion, the current studies demonstrated that the gender disparity of HCC is attributed by both androgen and estrogen sex hormone pathways, with distinct roles in each gender. Therefore, the ligand and the receptor factors of both sex hormones need to be included for assessing the relative risk of HCC patients of each gender.},
	language = {eng},
	journal = {Oncology},
	author = {Yeh, Shiou-Hwei and Chen, Pei-Jer},
	month = jul,
	year = {2010},
	pmid = {20616601},
	keywords = {Humans, Female, Liver Neoplasms, Male, Androgens, Animals, Carcinoma, Hepatocellular, Estrogens, Mice, Sex Factors},
	pages = {172--179},
}

@article{brayGlobalCancerStatistics2018,
	title = {Global cancer statistics 2018: {GLOBOCAN} estimates of incidence and mortality worldwide for 36 cancers in 185 countries},
	volume = {68},
	issn = {1542-4863},
	shorttitle = {Global cancer statistics 2018},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.3322/caac.21492},
	doi = {10.3322/caac.21492},
	abstract = {This article provides a status report on the global burden of cancer worldwide using the GLOBOCAN 2018 estimates of cancer incidence and mortality produced by the International Agency for Research on Cancer, with a focus on geographic variability across 20 world regions. There will be an estimated 18.1 million new cancer cases (17.0 million excluding nonmelanoma skin cancer) and 9.6 million cancer deaths (9.5 million excluding nonmelanoma skin cancer) in 2018. In both sexes combined, lung cancer is the most commonly diagnosed cancer (11.6\% of the total cases) and the leading cause of cancer death (18.4\% of the total cancer deaths), closely followed by female breast cancer (11.6\%), prostate cancer (7.1\%), and colorectal cancer (6.1\%) for incidence and colorectal cancer (9.2\%), stomach cancer (8.2\%), and liver cancer (8.2\%) for mortality. Lung cancer is the most frequent cancer and the leading cause of cancer death among males, followed by prostate and colorectal cancer (for incidence) and liver and stomach cancer (for mortality). Among females, breast cancer is the most commonly diagnosed cancer and the leading cause of cancer death, followed by colorectal and lung cancer (for incidence), and vice versa (for mortality); cervical cancer ranks fourth for both incidence and mortality. The most frequently diagnosed cancer and the leading cause of cancer death, however, substantially vary across countries and within each country depending on the degree of economic development and associated social and life style factors. It is noteworthy that high-quality cancer registry data, the basis for planning and implementing evidence-based cancer control programs, are not available in most low- and middle-income countries. The Global Initiative for Cancer Registry Development is an international partnership that supports better estimation, as well as the collection and use of local data, to prioritize and evaluate national cancer control efforts. CA: A Cancer Journal for Clinicians 2018;0:1-31. © 2018 American Cancer Society},
	language = {en},
	number = {6},
	urldate = {2023-04-26},
	journal = {CA: A Cancer Journal for Clinicians},
	author = {Bray, Freddie and Ferlay, Jacques and Soerjomataram, Isabelle and Siegel, Rebecca L. and Torre, Lindsey A. and Jemal, Ahmedin},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.3322/caac.21492},
	keywords = {cancer, epidemiology, incidence, survival},
	pages = {394--424},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/N4VPGVP4/Bray et al. - 2018 - Global cancer statistics 2018 GLOBOCAN estimates .pdf:application/pdf},
}

@article{mcglynnEpidemiologyHepatocellularCarcinoma2021,
	title = {Epidemiology of {Hepatocellular} {Carcinoma}},
	volume = {73},
	issn = {0270-9139},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7577946/},
	doi = {10.1002/hep.31288},
	abstract = {Liver cancer is a major contributor to the world’s cancer burden and incidence rates have increased in many countries in recent decades. As the principal histologic type of liver cancer, hepatocellular carcinoma (HCC) is responsible for the great majority of liver cancer diagnoses and deaths. Hepatitis B virus (HBV) and hepatitis C virus (HCV) remain, at present, the most important global risk factors for HCC, but it is likely their importance will decline in the coming years. The effect of HBV vaccination of newborns, already seen in young adults in some countries, will be more notable as vaccinated cohorts age. In addition, effective treatments for chronic infections with both HBV and HCV should contribute to declines in the rates of viral-associated HCC. Unfortunately, the prevalence of metabolic risk factors for HCC, including metabolic syndrome, obesity, type II diabetes and non-alcoholic fatty liver disease (NAFLD) are increasing and may jointly become the major cause of HCC globally. Excessive alcoholic consumption also remains an intractable risk factor, as does aflatoxin contamination of food crops in some parts of the world. While significant efforts in early diagnosis and better treatment are certainly needed for HCC, primary prevention efforts aimed at decreasing the prevalence and obesity and diabetes and controlling mycotoxin growth, and are just as urgently required.},
	number = {Suppl 1},
	urldate = {2023-04-26},
	journal = {Hepatology (Baltimore, Md.)},
	author = {McGlynn, Katherine A. and Petrick, Jessica L. and El-Serag, Hashem B.},
	month = jan,
	year = {2021},
	pmid = {32319693},
	pmcid = {PMC7577946},
	pages = {4--13},
	file = {PubMed Central Full Text PDF:/Users/noltinho/Zotero/storage/EURGJSXN/McGlynn et al. - 2021 - Epidemiology of Hepatocellular Carcinoma.pdf:application/pdf},
}

@article{abdelrazekLiverImagingReporting2020,
	title = {Liver {Imaging} {Reporting} and {Data} {System} {Version} 2018: {What} {Radiologists} {Need} to {Know}},
	volume = {44},
	issn = {0363-8715},
	shorttitle = {Liver {Imaging} {Reporting} and {Data} {System} {Version} 2018},
	url = {https://journals.lww.com/jcat/FullText/2020/03000/Liver_Imaging_Reporting_and_Data_System_Version.2.aspx},
	doi = {10.1097/RCT.0000000000000995},
	abstract = {In this article, we aim to review Liver Imaging Reporting and Data System version 18 (LI-RADS v2018). Hepatocellular carcinoma (HCC) is the most common primary hepatic malignancy. Liver Imaging Reporting and Data System developed for standardizing interpreting, reporting, and data collection of HCC describes 5 major features for accurate HCC diagnosis and several ancillary features, some favoring HCC in particular or malignancy in general and others favoring benignity. Untreated hepatic lesions LI-RADS affords 8 unique categories based on imaging appearance on computed tomography and magnetic resonance imaging, which indicate the possibility of HCC or malignancy with or without tumor in vein. Furthermore, LI-RADS defines 4 treatment response categories for treated HCCs after different locoregional therapy. These continuous recent updates on LI-RADS improve the communication between the radiologists and the clinicians for better management and patient outcome.},
	language = {en-US},
	number = {2},
	urldate = {2023-04-26},
	journal = {Journal of Computer Assisted Tomography},
	author = {Abdel Razek, Ahmed Abdel Khalek and El-Serougy, Lamiaa Galal and Saleh, Gehad Ahmad and Shabana, Walaa and Abd El-wahab, Rihame},
	month = apr,
	year = {2020},
	pages = {168},
	file = {Snapshot:/Users/noltinho/Zotero/storage/V7NR6AEY/Liver_Imaging_Reporting_and_Data_System_Version.2.html:text/html},
}

@article{mitchellLIRADSLiverImaging2015,
	title = {{LI}-{RADS} ({Liver} {Imaging} {Reporting} and {Data} {System}): {Summary}, discussion, and consensus of the {LI}-{RADS} {Management} {Working} {Group} and future directions},
	volume = {61},
	issn = {1527-3350},
	shorttitle = {{LI}-{RADS} ({Liver} {Imaging} {Reporting} and {Data} {System})},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hep.27304},
	doi = {10.1002/hep.27304},
	abstract = {To improve standardization and consensus regarding performance, interpreting, and reporting computed tomography (CT) and magnetic resonance imaging (MRI) examinations of the liver in patients at risk for hepatocellular carcinoma (HCC), LI-RADS (Liver Imaging Reporting and Data System) was launched in March 2011 and adopted by many clinical practices throughout the world. LI-RADS categorizes nodules recognized at CT or MRI, in patients at high risk of HCC, as definitively benign, probably benign, intermediate probability of being HCC, probably HCC, and definitively HCC (corresponding to LI-RADS categories 1-5). The LI-RADS Management Working Group, consisting of internationally recognized medical and surgical experts on HCC management, as well as radiologists involved in the development of LI-RADS, was convened to evaluate management implications related to radiological categorization of the estimated probability that a lesion will be ultimately diagnosed as HCC. In this commentary, we briefly review LI-RADS and the initial consensus of the LI-RADS Management Working Group reached during its deliberations in 2013. We then focus on initial discordance of LI-RADS with American Association for the Study of Liver Diseases and Organ Procurement Transplant Network guidelines, the basis for these differences, and how they are being addressed going forward to optimize reporting of CT and MRI findings in patients at risk for HCC and to increase consensus throughout the international community of physicians involved in the diagnosis and treatment of HCC. (Hepatology 2015;61:1056–1065)},
	language = {en},
	number = {3},
	urldate = {2023-04-26},
	journal = {Hepatology},
	author = {Mitchell, Donald G. and Bruix, Jordi and Sherman, Morris and Sirlin, Claude B.},
	year = {2015},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hep.27304},
	pages = {1056--1065},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/XKS9F4HA/Mitchell et al. - 2015 - LI-RADS (Liver Imaging Reporting and Data System).pdf:application/pdf;Snapshot:/Users/noltinho/Zotero/storage/LBSZDUSV/hep.html:text/html},
}

@article{santillanCTMRILiver2020,
	title = {{CT} and {MRI} of the liver for hepatocellular carcinoma},
	volume = {6},
	issn = {2394-5079},
	url = {https://hrjournal.net/article/view/3633},
	doi = {10.20517/2394-5079.2020.60},
	abstract = {CT and MRI of the liver for hepatocellular carcinoma},
	language = {en},
	urldate = {2023-04-26},
	journal = {Hepatoma Research},
	author = {Santillan, Cynthia},
	month = sep,
	year = {2020},
	note = {Publisher: OAE Publishing Inc.},
	pages = {63},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/2P3ZQUYU/Santillan - 2020 - CT and MRI of the liver for hepatocellular carcino.pdf:application/pdf},
}

@article{chenRecentProgressTreatment2020,
	title = {Recent progress in treatment of hepatocellular carcinoma},
	volume = {10},
	issn = {2156-6976},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7539784/},
	abstract = {Hepatocellular carcinoma (HCC) is the fourth leading cause of cancer-related death worldwide. In the past decade, there have been improvements in non-drug therapies and drug therapies for HCC treatment. Non-drug therapies include hepatic resection, liver transplantation, transarterial chemoembolization (TACE) and ablation. The former two surgical treatments are beneficial for patients with early and mid-stage HCC. As the first choice for non-surgical treatment, different TACE methods has been developed and widely used in combination therapy. Ablation has become an important alternative therapy for the treatment of small HCC or cases of unresectable surgery. Meanwhile, the drugs including small molecule targeted drugs like sorafenib and lenvatinib, monoclonal antibodies such as nivolumab are mainly used for the systematic treatment of advanced HCC. Besides strategies described above are recommended as first-line therapies due to their significant increase in mean overall survival, there are also potential drugs in clinical trials or under preclinical development. In addition, a number of potential preclinical surgical or adjuvant therapies are being studied, such as oncolytic virus, mesenchymal stem cells, biological clock, gut microbiome composition and peptide vaccine, all of which have shown different degrees of inhibition on HCC. With some potential anti-HCC drugs being reported, many promising therapeutic targets in related taxonomic signaling pathways including cell cycle, epigenetics, tyrosine kinase and so on that affect the progression of HCC have also been found. Together, the rational application of existing therapies and drugs as well as the new strategies will bring a bright future for the global cure of HCC in the coming decades.},
	number = {9},
	urldate = {2023-04-26},
	journal = {American Journal of Cancer Research},
	author = {Chen, Zhiqian and Xie, Hao and Hu, Mingming and Huang, Tianyi and Hu, Yanan and Sang, Na and Zhao, Yinglan},
	month = sep,
	year = {2020},
	pmid = {33042631},
	pmcid = {PMC7539784},
	pages = {2993--3036},
	file = {PubMed Central Full Text PDF:/Users/noltinho/Zotero/storage/U4BNUA6S/Chen et al. - 2020 - Recent progress in treatment of hepatocellular car.pdf:application/pdf},
}

@article{heimbachAASLDGuidelinesTreatment2018,
	title = {{AASLD} guidelines for the treatment of hepatocellular carcinoma},
	volume = {67},
	issn = {1527-3350},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/hep.29086},
	doi = {10.1002/hep.29086},
	language = {en},
	number = {1},
	urldate = {2023-04-26},
	journal = {Hepatology},
	author = {Heimbach, Julie K. and Kulik, Laura M. and Finn, Richard S. and Sirlin, Claude B. and Abecassis, Michael M. and Roberts, Lewis R. and Zhu, Andrew X. and Murad, M. Hassan and Marrero, Jorge A.},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/hep.29086},
	pages = {358--380},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/2RJCSHZU/Heimbach et al. - 2018 - AASLD guidelines for the treatment of hepatocellul.pdf:application/pdf;Snapshot:/Users/noltinho/Zotero/storage/G4C2XXD5/hep.html:text/html},
}

@article{sagiEnsembleLearningSurvey2018,
	title = {Ensemble learning: {A} survey},
	volume = {8},
	issn = {1942-4795},
	shorttitle = {Ensemble learning},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.1249},
	doi = {10.1002/widm.1249},
	abstract = {Ensemble methods are considered the state-of-the art solution for many machine learning challenges. Such methods improve the predictive performance of a single model by training multiple models and combining their predictions. This paper introduce the concept of ensemble learning, reviews traditional, novel and state-of-the-art ensemble methods and discusses current challenges and trends in the field. This article is categorized under: Algorithmic Development {\textgreater} Ensemble Methods Technologies {\textgreater} Machine Learning Technologies {\textgreater} Classification},
	language = {en},
	number = {4},
	urldate = {2023-04-26},
	journal = {WIREs Data Mining and Knowledge Discovery},
	author = {Sagi, Omer and Rokach, Lior},
	year = {2018},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/widm.1249},
	keywords = {boosting, classifier combination, ensemble models, machine-learning, mixtures of experts, multiple classifier system, random forest},
	pages = {e1249},
	file = {Full Text PDF:/Users/noltinho/Zotero/storage/GCJ579UK/Sagi and Rokach - 2018 - Ensemble learning A survey.pdf:application/pdf;Snapshot:/Users/noltinho/Zotero/storage/PXYJ65GV/widm.html:text/html},
}

@inproceedings{kern3DBoundingBox2021,
	title = {{3D} {Bounding} {Box} {Detection} in {Volumetric} {Medical} {Image} {Data}: {A} {Systematic} {Literature} {Review}},
	shorttitle = {{3D} {Bounding} {Box} {Detection} in {Volumetric} {Medical} {Image} {Data}},
	doi = {10.1109/ICIEA52957.2021.9436733},
	abstract = {This paper discusses current methods and trends for 3D bounding box detection in volumetric medical image data. For this purpose, an overview of relevant papers from recent years is given. 2D and 3D implementations are discussed and compared and multiple identified approaches for localizing anatomical structures are presented. The results show that most research recently focuses on Deep Learning methods, such as Convolutional Neural Networks instead of methods with manual feature engineering, e.g., Random Regression Forests. 2D and 3D implementations are equally common. An overview of bounding box detection options is presented and helps researchers to select the most promising approach for their target objects.},
	booktitle = {2021 {IEEE} 8th {International} {Conference} on {Industrial} {Engineering} and {Applications} ({ICIEA})},
	author = {Kern, Daria and Mastmeyer, Andre},
	month = apr,
	year = {2021},
	keywords = {Deep learning, medical imaging, 3D bounding box, 3D object detection, 3D object localization, Forestry, Industrial engineering, literature review, Location awareness, Manuals, Systematics, Three-dimensional displays},
	pages = {509--516},
	file = {IEEE Xplore Abstract Record:/Users/noltinho/Zotero/storage/TSC2NB84/stamp.html:text/html;IEEE Xplore Full Text PDF:/Users/noltinho/Zotero/storage/2UXJYV2F/Kern and Mastmeyer - 2021 - 3D Bounding Box Detection in Volumetric Medical Im.pdf:application/pdf},
}

@article{calderaroArtificialIntelligencePrevention2022,
	series = {Breakthroughs in {Hepatology}},
	title = {Artificial intelligence for the prevention and clinical management of hepatocellular carcinoma},
	volume = {76},
	issn = {0168-8278},
	url = {https://www.sciencedirect.com/science/article/pii/S0168827822000277},
	doi = {10.1016/j.jhep.2022.01.014},
	abstract = {Hepatocellular carcinoma (HCC) currently represents the fifth most common malignancy and the third-leading cause of cancer-related death worldwide, with incidence and mortality rates that are increasing. Recently, artificial intelligence (AI) has emerged as a unique opportunity to improve the full spectrum of HCC clinical care, by improving HCC risk prediction, diagnosis, and prognostication. AI approaches include computational search algorithms, machine learning (ML) and deep learning (DL) models. ML consists of a computer running repeated iterations of models, in order to progressively improve performance of a specific task, such as classifying an outcome. DL models are a subtype of ML, based on neural network structures that are inspired by the neuroanatomy of the human brain. A growing body of recent data now apply DL models to diverse data sources – including electronic health record data, imaging modalities, histopathology and molecular biomarkers – to improve the accuracy of HCC risk prediction, detection and prediction of treatment response. Despite the promise of these early results, future research is still needed to standardise AI data, and to improve both the generalisability and interpretability of results. If such challenges can be overcome, AI has the potential to profoundly change the way in which care is provided to patients with or at risk of HCC.},
	language = {en},
	number = {6},
	urldate = {2023-04-27},
	journal = {Journal of Hepatology},
	author = {Calderaro, Julien and Seraphin, Tobias Paul and Luedde, Tom and Simon, Tracey G.},
	month = jun,
	year = {2022},
	keywords = {Artificial intelligence, Deep learning, Machine learning, Liver cancer},
	pages = {1348--1361},
	file = {ScienceDirect Full Text PDF:/Users/noltinho/Zotero/storage/5HN2WVNH/Calderaro et al. - 2022 - Artificial intelligence for the prevention and cli.pdf:application/pdf;ScienceDirect Snapshot:/Users/noltinho/Zotero/storage/8HE4KKZD/S0168827822000277.html:text/html},
}
